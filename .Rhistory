library(gridExtra)
library(grid)
library(scales)
library(here)
#Using the new area selection script 'Coords_areas_catches_area1.R', We have now assigned a new F in the OM which calculates
#the relative distribution of catches from 2010 to 2024. We then need to run the script 'F_NIS gives' which outputs
#'relative.catch'. Relative catch is then fed into 'R/get_OM_parameters_NIS_fix.R' when the model is run.
source(here("scripts/analysis", "OM_areas.R"))
# Read parameters from stock assessment
parms <- readRDS(here("scripts/data/sandeel 1r", "area1r.rds"))
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(here)
# Read parameters from stock assessment
parms <- readRDS(here("scripts/data/sandeel 1r", "area1r.rds"))
install_github('nissandjac/smsR')
remove.packages("smsR", lib="C:/Program Files/R/R-4.4.3/library")
remove.packages("smsR", lib="C:/Program Files/R/R-4.4.3/library")
install_github('nissandjac/smsR')
library(smsR)
detach("package:smsR", unload = TRUE)
install_github('nissandjac/smsR')
library(smsR)
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(here)
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(here)
#install_github('nissandjac/smsR') - INSTALL UPDATES
#Using the new area selection script 'Coords_areas_catches_area1.R', We have now assigned a new F in the OM which calculates
#the relative distribution of catches from 2010 to 2024. We then need to run the script 'F_NIS gives' which outputs
#'relative.catch'. Relative catch is then fed into 'R/get_OM_parameters_NIS_fix.R' when the model is run.
source(here("scripts/analysis", "OM_areas.R"))
source("C:/Users/chris/Desktop/GIT/Paper/scripts/analysis/OM.R")
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(here)
#install_github('nissandjac/smsR') - INSTALL UPDATES
#Using the new area selection script 'Coords_areas_catches_area1.R', We have now assigned a new F in the OM which calculates
#the relative distribution of catches from 2010 to 2024. We then need to run the script 'F_NIS gives' which outputs
#'relative.catch'. Relative catch is then fed into 'R/get_OM_parameters_NIS_fix.R' when the model is run.
source(here("scripts/analysis", "OM_areas.R"))
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(here)
#install_github('nissandjac/smsR') - INSTALL UPDATES
#Using the new area selection script 'Coords_areas_catches_area1.R', We have now assigned a new F in the OM which calculates
#the relative distribution of catches from 2010 to 2024. We then need to run the script 'F_NIS gives' which outputs
#'relative.catch'. Relative catch is then fed into 'R/get_OM_parameters_NIS_fix.R' when the model is run.
source(here("scripts/analysis", "OM_areas.R"))
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(sf)
library(scales)
setwd("C:/Users/chris/Desktop/GIT/Paper")
source("C:/Users/chris/Desktop/DTU/R/ORIG/myfunctions.R")
cpue_data <- load("scripts/data/sandeel 1r/nage_space.Rdata") %>%
filter_all(all_vars(!is.na(.))) %>%  # Remove rows with NA
#filter_all(all_vars(trimws(.) != "")) %>%  # Remove rows with empty strings or spaces
#filter_all(all_vars(trimws(.) != ".")) %>%  # Remove rows with cells containing "     ."
filter(year >= 2010 & year <= 2024, )
cpue_data <- d.export$cpue %>%
filter_all(all_vars(!is.na(.))) %>%  # Remove rows with NA
#filter_all(all_vars(trimws(.) != "")) %>%  # Remove rows with empty strings or spaces
#filter_all(all_vars(trimws(.) != ".")) %>%  # Remove rows with cells containing "     ."
filter(year >= 2010 & year <= 2024, )
cpue_data <- load("scripts/data/sandeel 1r/nage_space.Rdata") %>%
filter(!is.na(cpue), cpue != 0, year >= 2010, year <= 2024)
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(sf)
library(scales)
setwd("C:/Users/chris/Desktop/GIT/Paper")
source("C:/Users/chris/Desktop/DTU/R/ORIG/myfunctions.R")
load("scripts/data/sandeel 1r/nage_space.Rdata")  # this loads an object into your environment
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0, year >= 2010, year <= 2024)
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0, as.numeric(as.character(year)) >= 2010, as.numeric(as.character(year)) <= 2024)
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0, as.numeric(as.character(year)) >= 2010, as.numeric(as.character(year)) <= 2024) %>%
filter(stock %in% c("SA 1")) %>%
names(Area = "stock")
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0, as.numeric(as.character(year)) >= 2010, as.numeric(as.character(year)) <= 2024) %>%
filter(stock %in% c("SA 1")) %>%
names(Area = stock)
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0, as.numeric(as.character(year)) >= 2010, as.numeric(as.character(year)) <= 2024) %>%
filter(stock %in% c("SA 1")) %>%
names(Area = d.export$stock)
View(cpue_data)
load("scripts/data/sandeel 1r/nage_space.Rdata")  # this loads an object into your environment
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0,
as.numeric(as.character(year)) >= 2010,
as.numeric(as.character(year)) <= 2024,
stock %in% c("SA 1")
) %>%
rename(Area = stock)
View(cpue_data)
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0,
as.numeric(as.character(year)) >= 2010,
as.numeric(as.character(year)) <= 2024,
stock %in% c("SA 1")
) %>%
rename(Area = stock, Year = year)
load("scripts/data/sandeel 1r/nage_space.Rdata")  # this loads an object into your environment
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0,
as.numeric(as.character(year)) >= 2010,
as.numeric(as.character(year)) <= 2024,
stock %in% c("SA 1")
) %>%
rename(area = stock)
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0,
as.numeric(as.character(year)) >= 2010,
as.numeric(as.character(year)) <= 2024,
stock %in% c("SA 1")
) %>%
rename(area = stock, age = Age)
print(cpue_data)
# Step 1: Load UK EEZ shapefile (same as before)
eez_data <- st_read('C:/Users/chris/Desktop/DTU/R/ORIG/DATA/SHAPEFILES/EEZ/EEZ_Land_v3_202030.shp') %>%
filter(UNION %in% c('Denmark','Germany','Netherlands','Sweden','United Kingdom', 'Norway', 'France', 'Belgium', 'Jersey', 'Guernsey'))
uk_eez <- eez_data %>% filter(UNION == "United Kingdom")
# Step 2: Convert cpue_data to sf object
cpue_sf <- st_as_sf(cpue_data, coords = c("long", "lat"), crs = st_crs(eez_data))
# Step 3: Define latitude threshold
latitude_threshold <- 54.5
# Step 4: Assign group classification
cpue_data$group <- NA
# Points inside UK EEZ
cpue_data$group[st_intersects(cpue_sf, uk_eez, sparse = FALSE)] <- "UK EEZ"
cpue_data$group[st_coordinates(cpue_sf)[,2] >= latitude_threshold & !st_intersects(cpue_sf, uk_eez, sparse = FALSE)] <- "EU North"
# Points outside but south
cpue_data$group[st_coordinates(cpue_sf)[,2] < latitude_threshold & !st_intersects(cpue_sf, uk_eez, sparse = FALSE)] <- "EU South"
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(sf)
library(scales)
setwd("C:/Users/chris/Desktop/GIT/Paper")
source("C:/Users/chris/Desktop/DTU/R/ORIG/myfunctions.R")
# Step 1: Load the two CSV files and clean up the data
#The reason why I am using "square_to_sandeel_areas_WKSAND16" is because the vgt file does not contain
#area information e.g. 1r, 2r, 3r etc. I am matching the area data with this existing data sheet to
#the vgt data to easily assign the area information to the vgt datasheet.
load("scripts/data/sandeel 1r/nage_space.Rdata")  # this loads an object into your environment
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0,
as.numeric(as.character(year)) >= 2010,
as.numeric(as.character(year)) <= 2024,
stock %in% c("SA 1")
) %>%
rename(area = stock, age = Age)
###############################################################################
############### Apply EEZ and region classification to cpue_data ##############
###############################################################################
# Step 1: Load UK EEZ shapefile (same as before)
eez_data <- st_read('C:/Users/chris/Desktop/DTU/R/ORIG/DATA/SHAPEFILES/EEZ/EEZ_Land_v3_202030.shp') %>%
filter(UNION %in% c('Denmark','Germany','Netherlands','Sweden','United Kingdom', 'Norway', 'France', 'Belgium', 'Jersey', 'Guernsey'))
uk_eez <- eez_data %>% filter(UNION == "United Kingdom")
# Step 2: Convert cpue_data to sf object
cpue_sf <- st_as_sf(cpue_data, coords = c("long", "lat"), crs = st_crs(eez_data))
# Step 3: Define latitude threshold
latitude_threshold <- 54.5
# Step 4: Assign group classification
cpue_data$group <- NA
# Points inside UK EEZ
cpue_data$group[st_intersects(cpue_sf, uk_eez, sparse = FALSE)] <- "UK EEZ"
cpue_data$group[st_coordinates(cpue_sf)[,2] >= latitude_threshold & !st_intersects(cpue_sf, uk_eez, sparse = FALSE)] <- "EU North"
# Points outside but south
cpue_data$group[st_coordinates(cpue_sf)[,2] < latitude_threshold & !st_intersects(cpue_sf, uk_eez, sparse = FALSE)] <- "EU South"
cpue_summary <- cpue_data %>%
group_by(group) %>%
summarise(cpue = sum(vgt, na.rm = TRUE))
cpue_summary <- cpue_data %>%
group_by(group) %>%
summarise(total_cpue = sum(cpue, na.rm = TRUE))
# View the summary
print(catch_summary)
# View the summary
print(cpue_summary)
cpue_summary <- cpue_data %>%
group_by(year, group) %>%
summarise(total_cpue = sum(cpue/1000, na.rm = TRUE))
# View the summary
print(cpue_summary)
cpue_by_year <- cpue_data %>%
group_by(year, group) %>%
summarise(total_cpue = sum(cpue/1000, na.rm = TRUE))
# View the summary
print(cpue_summary)
ggplot(cpue_by_year, aes(x = year, y = total_cpue, color = group)) +
geom_line(size = 1) +  # Plot lines for each group
labs(title = "Total CPUE Over Time",
x = "Year",
y = "Total Catch",
color = "Group") +
scale_color_manual(values = c("UK EEZ" = "#35465A", "EU North" = "#CC3300", "EU South" = "#008000")) +  # Custom colors for groups
# Use scale_y_continuous with label_number_si to format numbers in hundreds of thousands
#scale_y_continuous(labels = label_number(scale = 1e-5, suffix = "T", accuracy = 1)) +
# Adjust the x-axis to control the number of years shown
scale_x_continuous(breaks = seq(2010, 2024, by = 2)) +  # Shows every 2 years from 2010 to 2024
theme(
plot.title = element_text(size = 12, face = "bold"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 12 * 0.8),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12 * 0.8),
legend.position = "bottom",                # Move the legend to the bottom
legend.direction = "horizontal",           # Make the legend items display in a horizontal line
strip.text = element_text(size = 12 * 1.1),
panel.background = element_rect(fill = "#F0F2F2"),
plot.background = element_rect(fill = "white")
) +
guides(color = guide_legend(nrow = 1))
ggplot(cpue_by_year, aes(x = year, y = total_cpue, color = group)) +
geom_line(linewidth = 1) +  # Plot lines for each group
labs(title = "Total CPUE Over Time",
x = "Year",
y = "Total Catch",
color = "Group") +
scale_color_manual(values = c("UK EEZ" = "#35465A", "EU North" = "#CC3300", "EU South" = "#008000")) +  # Custom colors for groups
# Use scale_y_continuous with label_number_si to format numbers in hundreds of thousands
#scale_y_continuous(labels = label_number(scale = 1e-5, suffix = "T", accuracy = 1)) +
# Adjust the x-axis to control the number of years shown
scale_x_continuous(breaks = seq(2010, 2024, by = 2)) +  # Shows every 2 years from 2010 to 2024
theme(
plot.title = element_text(size = 12, face = "bold"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 12 * 0.8),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12 * 0.8),
legend.position = "bottom",                # Move the legend to the bottom
legend.direction = "horizontal",           # Make the legend items display in a horizontal line
strip.text = element_text(size = 12 * 1.1),
panel.background = element_rect(fill = "#F0F2F2"),
plot.background = element_rect(fill = "white")
) +
guides(color = guide_legend(nrow = 1))
rlang::last_trace()
cpue_by_year <- cpue_data %>%
mutate(year = as.numeric(as.character(year)))
group_by(year, group) %>%
summarise(total_cpue = sum(cpue/1000, na.rm = TRUE))
cpue_by_year <- cpue_data %>%
group_by(year, group) %>%
summarise(total_cpue = sum(cpue/1000, na.rm = TRUE)) %>%
mutate(year = as.numeric(as.character(year)))
ggplot(cpue_by_year, aes(x = year, y = total_cpue, color = group)) +
geom_line(linewidth = 1) +  # Plot lines for each group
labs(title = "Total CPUE Over Time",
x = "Year",
y = "Total Catch",
color = "Group") +
scale_color_manual(values = c("UK EEZ" = "#35465A", "EU North" = "#CC3300", "EU South" = "#008000")) +  # Custom colors for groups
# Use scale_y_continuous with label_number_si to format numbers in hundreds of thousands
#scale_y_continuous(labels = label_number(scale = 1e-5, suffix = "T", accuracy = 1)) +
# Adjust the x-axis to control the number of years shown
scale_x_continuous(breaks = seq(2010, 2024, by = 2)) +  # Shows every 2 years from 2010 to 2024
theme(
plot.title = element_text(size = 12, face = "bold"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 12 * 0.8),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12 * 0.8),
legend.position = "bottom",                # Move the legend to the bottom
legend.direction = "horizontal",           # Make the legend items display in a horizontal line
strip.text = element_text(size = 12 * 1.1),
panel.background = element_rect(fill = "#F0F2F2"),
plot.background = element_rect(fill = "white")
) +
guides(color = guide_legend(nrow = 1))
ggplot(cpue_by_year, aes(x = year, y = total_cpue, color = group)) +
geom_line(linewidth = 3) +  # Plot lines for each group
labs(title = "Total CPUE Over Time",
x = "Year",
y = "Total Catch",
color = "Group") +
scale_color_manual(values = c("UK EEZ" = "#35465A", "EU North" = "#CC3300", "EU South" = "#008000")) +  # Custom colors for groups
# Use scale_y_continuous with label_number_si to format numbers in hundreds of thousands
#scale_y_continuous(labels = label_number(scale = 1e-5, suffix = "T", accuracy = 1)) +
# Adjust the x-axis to control the number of years shown
scale_x_continuous(breaks = seq(2010, 2024, by = 2)) +  # Shows every 2 years from 2010 to 2024
theme(
plot.title = element_text(size = 12, face = "bold"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 12 * 0.8),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12 * 0.8),
legend.position = "bottom",                # Move the legend to the bottom
legend.direction = "horizontal",           # Make the legend items display in a horizontal line
strip.text = element_text(size = 12 * 1.1),
panel.background = element_rect(fill = "#F0F2F2"),
plot.background = element_rect(fill = "white")
) +
guides(color = guide_legend(nrow = 1))
cpue_by_year <- cpue_data %>%
group_by(year, group) %>%
summarise(total_cpue = sum(cpue, na.rm = TRUE)) %>%
mutate(year = as.numeric(as.character(year)))
ggplot(cpue_by_year, aes(x = year, y = total_cpue, color = group)) +
geom_line(linewidth = 3) +  # Plot lines for each group
labs(title = "Total CPUE Over Time",
x = "Year",
y = "Total Catch",
color = "Group") +
scale_color_manual(values = c("UK EEZ" = "#35465A", "EU North" = "#CC3300", "EU South" = "#008000")) +  # Custom colors for groups
# Use scale_y_continuous with label_number_si to format numbers in hundreds of thousands
#scale_y_continuous(labels = label_number(scale = 1e-5, suffix = "T", accuracy = 1)) +
# Adjust the x-axis to control the number of years shown
scale_x_continuous(breaks = seq(2010, 2024, by = 2)) +  # Shows every 2 years from 2010 to 2024
theme(
plot.title = element_text(size = 12, face = "bold"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 12 * 0.8),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12 * 0.8),
legend.position = "bottom",                # Move the legend to the bottom
legend.direction = "horizontal",           # Make the legend items display in a horizontal line
strip.text = element_text(size = 12 * 1.1),
panel.background = element_rect(fill = "#F0F2F2"),
plot.background = element_rect(fill = "white")
) +
guides(color = guide_legend(nrow = 1))
View(cpue_data)
library(tidyverse)
library(dplyr)
library(reshape2)
library(usethis)
library(devtools)
library(TMB)
library(patchwork) #THIS IS NEEDED FOR smsR to work!
library(abind) #THIS IS NEEDED FOR smsR to work!
library(smsR)
library(ggplot2)
library(gridExtra)
library(grid)
library(scales)
library(sf)
library(scales)
setwd("C:/Users/chris/Desktop/GIT/Paper")
source("C:/Users/chris/Desktop/DTU/R/ORIG/myfunctions.R")
# Step 1: Load the two CSV files and clean up the data
#The reason why I am using "square_to_sandeel_areas_WKSAND16" is because the vgt file does not contain
#area information e.g. 1r, 2r, 3r etc. I am matching the area data with this existing data sheet to
#the vgt data to easily assign the area information to the vgt datasheet.
load("scripts/data/sandeel 1r/nage_space.Rdata")  # this loads an object into your environment
cpue_data <- d.export %>%
filter(!is.na(cpue), cpue != 0,
as.numeric(as.character(year)) >= 2010,
as.numeric(as.character(year)) <= 2024,
stock %in% c("SA 1")
) %>%
rename(area = stock, age = Age)
View(cpue_data)
# Dredge clean #
#remotes::install_github("DTUAqua/DATRAS/DATRAS")
#remotes::install_github("casperwberg/surveyIndex/surveyIndex")
library(surveyIndex)
library(DATRAS)
library(icesDatras)
#library(rgdal)
library(maps)
library(tidyverse)
library(sf)
library(sp)
wd <- "C:/Users/chris/Desktop/DPPO/ICES-DATRAS/NIS/"
# Download new data for sandeel
downloadExchange('NSSS', years = 2008:2024)
downloadExchange()
#read
# Bind the two together so we get 2004-2008
d=readExchange(file.path(wd,"/ALL_TBM_2004-2022.zip")) #new data
# Subset by species
d <- subset(d, Species == "Ammodytes marinus")
View(d)
# # Now run the 2008:2024
# d2 <- readExchangeDir(file.path(wd, 'index_reconstruction/NSSS'))
# Add dates and wave height to data frame
d[[2]]$date = as.Date(paste(d$Year,d$month,d$Day,sep="-"),format="%Y-%m-%d")
d <- addSpectrum(d, by = 1)
d$lat
d$lon
d$Nage
fil = paste('Version9inclSkagerrak',".shp", sep = "")
path3 = file.path(wd,"shp/")
path3<-file.path(path3,fil)
shape <- st_read(dsn = file.path(wd, 'shp/'), layer = 'Version9inclSkagerrak')  #sandeel area shape files
d <- addSpatialData(d, path3)
ages <- 0:4
d <- DATRAS::addNage(d, ages = ages,model="cra ~ Year*SP_ID*LngtCm")
#d <- DATRAS::addNage(d, ages = 0:4, model = "cra ~ s(LngtCm, k = 4) + Year")
# s() is a smoothing function (from the mgcv package) that models non-linear relationships.
# grid <- getGrid(d, nLon=40)
# ## set max basis dim for spatial smooths by age, P=positive and Z=zero/absence.
# ## These are set relatively low here to speed up the example
# kvP <- c(50,50)
# kvZ <- kvP / 2;
# mP <- rep("Year+s(lon,lat,k=kvecP[a],bs='ts')+offset(log(HaulDur))",length(ages)  );
# mZ <- rep("Year+s(lon,lat,k=kvecZ[a],bs='ts')+offset(log(HaulDur))",length(ages)  );
#
# sandeel_ns_ibts <- getSurveyIdx(d,ages=ages,myids=grid[[3]],cutOff=0.001,kvecP=kvP,kvecZ=kvZ,
#                                 modelZ=mZ,modelP=mP,mc.cores=1) ## if errors are encountered, debug with mc.cores=1
#### Create a new data  frame for me
d.export <- data.frame(Nage = as.matrix(d$Nage),
lat = d$lat,
long = d$lon,
year = d$Year,
stock = d$SP_ID) %>% pivot_longer(1:5, names_to = 'Age', values_to = 'cpue')
d.export$Age[d.export$Age == 'Nage.0'] <- '0'
d.export$Age[d.export$Age == 'Nage.1'] <- '1'
d.export$Age[d.export$Age == 'Nage.2'] <- '2'
d.export$Age[d.export$Age == 'Nage.3'] <- '3'
d.export$Age[d.export$Age == 'Nage.4.'] <- '4'
ggplot(d.export[d.export$Age == 0,], aes(x = long, y = lat, fill = log(cpue+1)))+
geom_tile(width = .2, height = .2)+facet_wrap(~year)+theme_classic()
??downloadExchange
# Download new data for sandeel
downloadExchange('NSSS', years = 2008:2024)
